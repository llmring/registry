[
  {
    "dollars_per_million_tokens_input": 2,
    "supports_function_calling": true,
    "max_output_tokens": 32768,
    "max_input_tokens": 1014808,
    "cache_storage_cost_per_million_tokens_per_hour": 0.5,
    "model_aliases": [],
    "supports_caching": true,
    "supports_json_mode": true,
    "display_name": "GPT-4.1",
    "dollars_per_million_tokens_cached_input": 0.5,
    "supports_parallel_tool_calls": true,
    "supports_long_context_pricing": false,
    "is_active": true,
    "description": "GPT-4.1 excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.",
    "supports_vision": true,
    "model_name": "gpt-4.1",
    "supports_streaming": true,
    "supports_documents": false,
    "supports_thinking": false,
    "dollars_per_million_tokens_output": 8
  },
  {
    "dollars_per_million_tokens_output": 0.4,
    "model_name": "gpt-5-nano",
    "supports_function_calling": true,
    "max_input_tokens": 272000,
    "supports_vision": true,
    "display_name": "GPT-5 nano",
    "dollars_per_million_tokens_cached_input": 0.005,
    "is_active": true,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 0.05,
    "supports_json_mode": true,
    "supports_thinking": true,
    "supports_streaming": true,
    "max_output_tokens": 128000,
    "description": "GPT-5 Nano is our fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
    "model_aliases": []
  },
  {
    "dollars_per_million_tokens_cached_input": 2.5,
    "supports_thinking": true,
    "dollars_per_million_tokens_output": 40,
    "supports_streaming": true,
    "description": "o3-deep-research is our most advanced model for deep research, designed to tackle complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data\u2014brought in through MCP connectors.",
    "max_output_tokens": 100000,
    "model_aliases": [],
    "supports_vision": true,
    "supports_json_mode": false,
    "max_input_tokens": 100000,
    "supports_documents": true,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 10,
    "supports_function_calling": false,
    "is_active": true,
    "model_name": "o3-deep-research",
    "display_name": "o3-deep-research"
  },
  {
    "model_aliases": [],
    "supports_thinking": true,
    "model_name": "o4-mini-deep-research",
    "supports_documents": true,
    "dollars_per_million_tokens_output": 8,
    "max_input_tokens": 100000,
    "supports_json_mode": false,
    "display_name": "o4-mini-deep-research",
    "max_output_tokens": 100000,
    "supports_vision": true,
    "dollars_per_million_tokens_input": 2,
    "dollars_per_million_tokens_cached_input": 0.5,
    "supports_streaming": true,
    "description": "o4-mini-deep-research is our faster, more affordable deep research model\u2014ideal for tackling complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data, brought in through MCP connectors.",
    "is_active": true,
    "supports_caching": true,
    "supports_function_calling": false
  },
  {
    "supports_caching": true,
    "dollars_per_million_tokens_input": 0.25,
    "max_output_tokens": 128000,
    "dollars_per_million_tokens_cached_input": 0.025,
    "supports_streaming": true,
    "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
    "is_active": true,
    "max_input_tokens": 272000,
    "supports_thinking": true,
    "supports_function_calling": true,
    "supports_long_context_pricing": false,
    "dollars_per_million_tokens_output": 2,
    "supports_vision": true,
    "supports_documents": false,
    "supports_json_mode": true,
    "display_name": "GPT-5 mini",
    "model_aliases": [
      "gpt-5-mini"
    ],
    "model_name": "gpt-5-mini-2025-08-07"
  },
  {
    "supports_json_mode": true,
    "dollars_per_million_tokens_input": 1.25,
    "model_name": "gpt-5-2025-08-07",
    "display_name": "GPT-5",
    "supports_streaming": true,
    "supports_caching": true,
    "dollars_per_million_tokens_cached_input": 0.125,
    "model_aliases": [
      "gpt-5"
    ],
    "supports_function_calling": true,
    "max_input_tokens": 272000,
    "supports_thinking": true,
    "supports_vision": true,
    "is_active": true,
    "max_output_tokens": 128000,
    "description": "GPT-5 is our flagship model for coding, reasoning, and agentic tasks across domains.",
    "dollars_per_million_tokens_output": 10
  },
  {
    "dollars_per_million_tokens_cached_input": 0.125,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 1.25,
    "dollars_per_million_tokens_output": 10,
    "model_name": "gpt-5-chat-latest",
    "display_name": "gpt-5-chat-latest"
  },
  {
    "dollars_per_million_tokens_output": 1.6,
    "display_name": "gpt-4.1-mini",
    "supports_caching": true,
    "dollars_per_million_tokens_cached_input": 0.1,
    "model_name": "gpt-4.1-mini",
    "dollars_per_million_tokens_input": 0.4
  },
  {
    "dollars_per_million_tokens_output": 0.4,
    "supports_caching": true,
    "display_name": "gpt-4.1-nano",
    "dollars_per_million_tokens_cached_input": 0.025,
    "model_name": "gpt-4.1-nano",
    "dollars_per_million_tokens_input": 0.1
  },
  {
    "dollars_per_million_tokens_input": 2.5,
    "display_name": "gpt-4o",
    "dollars_per_million_tokens_cached_input": 1.25,
    "model_name": "gpt-4o",
    "dollars_per_million_tokens_output": 10,
    "supports_caching": true
  },
  {
    "model_name": "gpt-4o-2024-05-13",
    "dollars_per_million_tokens_input": 5,
    "dollars_per_million_tokens_output": 15,
    "supports_caching": false,
    "display_name": "gpt-4o-2024-05-13"
  },
  {
    "supports_caching": true,
    "dollars_per_million_tokens_output": 0.6,
    "dollars_per_million_tokens_input": 0.15,
    "dollars_per_million_tokens_cached_input": 0.075,
    "model_name": "gpt-4o-mini",
    "display_name": "gpt-4o-mini"
  },
  {
    "dollars_per_million_tokens_cached_input": 0.4,
    "dollars_per_million_tokens_input": 4,
    "model_name": "gpt-realtime",
    "dollars_per_million_tokens_output": 16,
    "supports_caching": true,
    "display_name": "gpt-realtime"
  },
  {
    "dollars_per_million_tokens_output": 20,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 5,
    "display_name": "gpt-4o-realtime-preview",
    "dollars_per_million_tokens_cached_input": 2.5,
    "model_name": "gpt-4o-realtime-preview"
  },
  {
    "dollars_per_million_tokens_output": 2.4,
    "supports_caching": true,
    "model_name": "gpt-4o-mini-realtime-preview",
    "display_name": "gpt-4o-mini-realtime-preview",
    "dollars_per_million_tokens_input": 0.6,
    "dollars_per_million_tokens_cached_input": 0.3
  },
  {
    "dollars_per_million_tokens_input": 2.5,
    "model_name": "gpt-audio",
    "supports_caching": false,
    "display_name": "gpt-audio",
    "dollars_per_million_tokens_output": 10
  },
  {
    "model_name": "gpt-4o-audio-preview",
    "dollars_per_million_tokens_input": 2.5,
    "dollars_per_million_tokens_output": 10,
    "supports_caching": false,
    "display_name": "gpt-4o-audio-preview"
  },
  {
    "dollars_per_million_tokens_output": 0.6,
    "supports_caching": false,
    "dollars_per_million_tokens_input": 0.15,
    "display_name": "gpt-4o-mini-audio-preview",
    "model_name": "gpt-4o-mini-audio-preview"
  },
  {
    "dollars_per_million_tokens_cached_input": 7.5,
    "dollars_per_million_tokens_input": 15,
    "model_name": "o1",
    "display_name": "o1",
    "dollars_per_million_tokens_output": 60,
    "supports_caching": true
  },
  {
    "dollars_per_million_tokens_output": 600,
    "display_name": "o1-pro",
    "supports_caching": false,
    "model_name": "o1-pro",
    "dollars_per_million_tokens_input": 150
  },
  {
    "dollars_per_million_tokens_output": 80,
    "model_name": "o3-pro",
    "supports_caching": false,
    "display_name": "o3-pro",
    "dollars_per_million_tokens_input": 20
  },
  {
    "model_name": "o3",
    "dollars_per_million_tokens_output": 8,
    "dollars_per_million_tokens_cached_input": 0.5,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 2,
    "display_name": "o3"
  },
  {
    "model_name": "o4-mini",
    "dollars_per_million_tokens_cached_input": 0.275,
    "supports_caching": true,
    "display_name": "o4-mini",
    "dollars_per_million_tokens_input": 1.1,
    "dollars_per_million_tokens_output": 4.4
  },
  {
    "model_name": "o3-mini",
    "supports_caching": true,
    "dollars_per_million_tokens_output": 4.4,
    "dollars_per_million_tokens_cached_input": 0.55,
    "display_name": "o3-mini",
    "dollars_per_million_tokens_input": 1.1
  },
  {
    "dollars_per_million_tokens_output": 4.4,
    "model_name": "o1-mini",
    "dollars_per_million_tokens_cached_input": 0.55,
    "supports_caching": true,
    "dollars_per_million_tokens_input": 1.1,
    "display_name": "o1-mini"
  },
  {
    "display_name": "codex-mini-latest",
    "dollars_per_million_tokens_input": 1.5,
    "dollars_per_million_tokens_output": 6,
    "model_name": "codex-mini-latest",
    "dollars_per_million_tokens_cached_input": 0.375,
    "supports_caching": true
  },
  {
    "supports_caching": false,
    "dollars_per_million_tokens_input": 0.15,
    "dollars_per_million_tokens_output": 0.6,
    "display_name": "gpt-4o-mini-search-preview",
    "model_name": "gpt-4o-mini-search-preview"
  },
  {
    "display_name": "gpt-4o-search-preview",
    "dollars_per_million_tokens_output": 10,
    "supports_caching": false,
    "dollars_per_million_tokens_input": 2.5,
    "model_name": "gpt-4o-search-preview"
  },
  {
    "display_name": "computer-use-preview",
    "dollars_per_million_tokens_output": 12,
    "supports_caching": false,
    "dollars_per_million_tokens_input": 3,
    "model_name": "computer-use-preview"
  }
]