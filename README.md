# LLMRing Registry

> ‚ö†Ô∏è Pre-release notice
>
> The pricing, token limits, and capabilities in this registry are under active validation and may be inaccurate. Do not rely on these numbers for production decisions. Always verify against the providers' official documentation.

The official model registry for LLMRing - providing up-to-date pricing, capabilities, and metadata for all major LLM providers.

## Overview

The LLMRing Registry is the source of truth for model information across the LLMRing ecosystem. It maintains accurate model data extracted from provider documentation, serving it through GitHub Pages for global, free access.

**Key Features:**
- ü§ñ **Claude-guided extraction** - Interactive, high-accuracy model extraction
- üì¶ **Versioned JSON files** - Historical snapshots with full audit trail
- üîÑ **Smart merging** - Preserves existing data when updating
- üåê **Served via GitHub Pages** at `https://llmring.github.io/registry/`
- üîì **No API keys required** for access

## Architecture

```
Registry (This Repo)
‚îú‚îÄ‚îÄ sources/            # Source documentation (audit trail)
‚îÇ   ‚îú‚îÄ‚îÄ anthropic/     # Anthropic model docs (markdown)
‚îÇ   ‚îú‚îÄ‚îÄ openai/        # OpenAI model docs
‚îÇ   ‚îî‚îÄ‚îÄ google/        # Google model docs
‚îú‚îÄ‚îÄ drafts/            # Pending model updates
‚îÇ   ‚îî‚îÄ‚îÄ *.draft.json   # Generated by Claude
‚îú‚îÄ‚îÄ Review & Promotion
‚îÇ   ‚îú‚îÄ‚îÄ Diff generation (review-draft)
‚îÇ   ‚îú‚îÄ‚îÄ Smart merging (promote)
‚îÇ   ‚îî‚îÄ‚îÄ Version management
‚îî‚îÄ‚îÄ Output
    ‚îú‚îÄ‚îÄ models/        # Current production models
    ‚îú‚îÄ‚îÄ pages/         # Versioned archives for GitHub Pages
    ‚îî‚îÄ‚îÄ manifest.json  # Registry metadata
```

## Setup

### Installation

```bash
# Clone the repository
git clone https://github.com/llmring/registry.git
cd registry

# Install with uv (recommended)
uv sync
uv pip install -e .
```

No API keys or browser automation required! Model extraction is done interactively with Claude.

## How to Update Models

The registry uses a **Claude-guided interactive workflow** for maximum accuracy and simplicity.

### Complete Workflow

When providers release new models or change pricing, use the `update-registry` skill:

```
1. In Claude Code: "Update the anthropic registry"

2. Claude will guide you through:
   - Save the latest documentation to sources/anthropic/YYYY-MM-DD-models.md
   - Claude reads and extracts models
   - Review the changes
   - Promote to production
   - Commit to git
```

### Manual Step-by-Step

If you prefer to run commands manually:

#### 1. Save Source Documentation

Visit the provider's documentation page and save it as markdown:

```bash
# Anthropic
# Visit: https://docs.anthropic.com/en/docs/about-claude/models/overview
# Save to: sources/anthropic/2025-10-20-models.md

# OpenAI
# Visit: https://platform.openai.com/docs/models
# Save to: sources/openai/2025-10-20-models.md

# Google
# Visit: https://ai.google.dev/gemini-api/docs/models
# Save to: sources/google/2025-10-20-models.md
```

#### 2. Extract Models (with Claude)

Create a draft JSON file in `drafts/{provider}.{date}.draft.json` by reading the source file and extracting model information following the registry schema.

See `.claude/skills/update-registry/skill.md` for the complete extraction schema and guidelines.

#### 3. Review Changes

```bash
# Compare draft against current production
uv run llmring-registry review-draft --provider anthropic

# This creates drafts/anthropic.YYYY-MM-DD.draft.diff.json showing:
# - Models added
# - Models removed
# - Fields changed
```

#### 4. Promote to Production

```bash
# Promote draft to production
uv run llmring-registry promote --provider anthropic
```

This will:
- Merge draft into current registry (preserving existing fields with non-null values)
- Increment version number
- Create versioned snapshot at `pages/anthropic/v/{N}/`
- Archive source docs
- Update manifest

#### 5. Commit Changes

```bash
git add sources/anthropic/ pages/anthropic/ models/anthropic.json manifest.json
git commit -m "Update Anthropic models - 2025-10-20

Added new models:
- Claude Sonnet 4.5
- Claude Haiku 4.5

Updated all existing models with:
- Added caching support pricing
- Added extended thinking support"
git push
```

## Directory Structure

```
registry/
‚îú‚îÄ‚îÄ .claude/
‚îÇ   ‚îî‚îÄ‚îÄ skills/
‚îÇ       ‚îî‚îÄ‚îÄ update-registry/   # Claude skill for guided updates
‚îÇ           ‚îî‚îÄ‚îÄ skill.md
‚îú‚îÄ‚îÄ sources/                   # Source documents (audit trail)
‚îÇ   ‚îú‚îÄ‚îÄ anthropic/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ YYYY-MM-DD-models.md
‚îÇ   ‚îú‚îÄ‚îÄ openai/
‚îÇ   ‚îî‚îÄ‚îÄ google/
‚îú‚îÄ‚îÄ drafts/                    # Extracted model drafts pending review
‚îÇ   ‚îú‚îÄ‚îÄ *.draft.json
‚îÇ   ‚îî‚îÄ‚îÄ *.draft.diff.json
‚îú‚îÄ‚îÄ models/                    # Current production models (local)
‚îÇ   ‚îú‚îÄ‚îÄ anthropic.json
‚îÇ   ‚îú‚îÄ‚îÄ openai.json
‚îÇ   ‚îî‚îÄ‚îÄ google.json
‚îî‚îÄ‚îÄ pages/                     # Versioned archives for GitHub Pages
    ‚îî‚îÄ‚îÄ {provider}/
        ‚îú‚îÄ‚îÄ models.json        # Current version
        ‚îî‚îÄ‚îÄ v/                 # Historical versions
            ‚îî‚îÄ‚îÄ {N}/
                ‚îú‚îÄ‚îÄ models.json
                ‚îî‚îÄ‚îÄ sources/   # Archived source docs
```

## CLI Commands

### Core Commands

```bash
# Review a draft (generates diff)
uv run llmring-registry review-draft --provider anthropic

# Promote draft to production
uv run llmring-registry promote --provider anthropic

# List available drafts
uv run llmring-registry list-drafts

# Show registry statistics
uv run llmring-registry stats --provider anthropic
```

### Utility Commands

```bash
# Normalize draft JSON (clean up formatting)
uv run llmring-registry normalize --provider anthropic

# Export registry data
uv run llmring-registry export --output markdown > models.md
uv run llmring-registry export --output json
```

## Model Schema

Each provider's JSON file contains models in dictionary format with `provider:model` keys for fast lookup:

```json
{
  "provider": "anthropic",
  "version": 4,
  "updated_at": "2025-10-20T00:00:00Z",
  "extraction_date": "2025-10-20T12:00:00Z",
  "sources": {
    "documents": 1,
    "models_extracted": 10
  },
  "models": {
    "anthropic:claude-sonnet-4-5-20250929": {
      "provider": "anthropic",
      "model_name": "claude-sonnet-4-5-20250929",
      "display_name": "Claude Sonnet 4.5",
      "description": "Our best model for complex agents and coding",
      "model_aliases": ["claude-sonnet-4-5"],

      // Pricing (required)
      "dollars_per_million_tokens_input": 3.0,
      "dollars_per_million_tokens_output": 15.0,

      // Optional pricing fields
      "dollars_per_million_tokens_cache_write_5m": 3.75,
      "dollars_per_million_tokens_cache_write_1h": 6.0,
      "dollars_per_million_tokens_cache_read": 0.3,
      "long_context_threshold_tokens": 200000,

      // Token limits (required)
      "max_input_tokens": 136000,
      "max_output_tokens": 64000,

      // Capabilities (boolean)
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": true,
      "supports_streaming": true,
      "supports_caching": true,
      "supports_thinking": true,
      "is_active": true,

      // Metadata
      "api_endpoint": "chat",
      "tool_call_format": "anthropic",
      "max_temperature": 1.0,
      "min_temperature": 0.0
    }
  }
}
```

## Key Design Decisions

### Why Claude-Guided Extraction?

The previous system used an automated LLM pipeline with multi-document voting and validation. This was over-engineered for a task that happens ~once per month.

**New approach benefits:**
- ‚úÖ **More accurate** - Claude can reason about edge cases interactively
- ‚úÖ **Simpler** - 65% less code to maintain
- ‚úÖ **Faster** - No pipeline overhead or retries
- ‚úÖ **Debuggable** - You see the extraction happen in real-time
- ‚úÖ **Interactive** - Can ask questions and verify as you go

### Smart Merge Logic

When promoting drafts, the system:
- ‚úÖ Updates fields where draft has non-null values
- ‚úÖ Preserves production fields when draft has null
- ‚úÖ Prevents accidental data loss
- ‚úÖ Maintains backward compatibility

Example: If production has `api_endpoint: "chat"` and draft has `api_endpoint: null`, the production value is preserved.

## Troubleshooting

### Common Issues

**Problem**: Can't find latest draft
```bash
# Solution: Check drafts directory
ls -lt drafts/*.draft.json

# Or use list-drafts command
uv run llmring-registry list-drafts
```

**Problem**: Promote fails with validation error
```bash
# Solution: Check the error message carefully
# Common issues:
# - Missing required fields (model_name, pricing)
# - Invalid JSON syntax
# - Wrong data types

# Manually edit the draft JSON and re-run promote
```

**Problem**: Changes not showing up
```bash
# Solution: Check if draft was actually different from production
uv run llmring-registry review-draft --provider anthropic

# If no changes, promote will skip
```

## Integration with LLMRing

The registry serves as the data source for the entire LLMRing ecosystem:

1. **Static Hosting**: JSON files served via GitHub Pages
2. **Registry URL**: `https://llmring.github.io/registry/`
3. **Manifest**: Contains version info and provider index
4. **Updates**: On-demand via Claude-guided workflow

Client usage:
```python
from llmring import LLMRing

# Automatically fetches latest registry
ring = LLMRing()

# Get available models
models = ring.get_available_models()
```

## Contributing

We welcome contributions! The simplest way to contribute is to update model data when providers release changes.

### Adding a New Provider

1. Create directory: `sources/{provider}/`
2. Save documentation to markdown
3. Use Claude to extract models following the schema
4. Review, promote, and commit

## License

MIT License - see [LICENSE](LICENSE) for details.

## Links

- **Registry Data**: https://llmring.github.io/registry/
- **Main Project**: https://github.com/llmring/llmring
- **Documentation**: https://llmring.ai/docs

---

*Built with ‚ù§Ô∏è by the LLMRing team*
