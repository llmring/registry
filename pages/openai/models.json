{
  "provider": "openai",
  "extraction_date": "2025-10-12T20:14:56.569350",
  "sources": {
    "documents": 19,
    "png_files": 19,
    "pdf_files": 0,
    "md_files": 0,
    "models_extracted": 19
  },
  "models": {
    "openai:gpt-4.1": {
      "provider": "openai",
      "model_name": "gpt-4.1",
      "display_name": "GPT-4.1",
      "description": "Smartest non-reasoning model. GPT-4.1 excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "max_input_tokens": 967232,
      "max_output_tokens": 32768,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": true,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-5-nano": {
      "provider": "openai",
      "model_name": "gpt-5-nano",
      "display_name": "GPT-5 nano",
      "description": "Fastest, most cost-efficient version of GPT-5. It's great for summarization and classification tasks.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 0.05,
      "dollars_per_million_tokens_output": 0.05,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": true,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o3-deep-research": {
      "provider": "openai",
      "model_name": "o3-deep-research",
      "display_name": "o3-deep-research",
      "description": "o3-deep-research is our most advanced model for deep research, designed to tackle complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data\u2014brought in through MCP connectors.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 10.0,
      "dollars_per_million_tokens_output": 40.0,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o4-mini-deep-research": {
      "provider": "openai",
      "model_name": "o4-mini-deep-research",
      "display_name": "o4-mini-deep-research",
      "description": "o4-mini-deep-research is our faster, more affordable deep research model\u2014ideal for tackling complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data, brought in through MCP connectors.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-5-mini-2025-08-07": {
      "provider": "openai",
      "model_name": "gpt-5-mini-2025-08-07",
      "display_name": "GPT-5 mini",
      "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
      "model_aliases": [
        "gpt-5-mini"
      ],
      "dollars_per_million_tokens_input": 0.25,
      "dollars_per_million_tokens_output": 2.0,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-5-2025-08-07": {
      "provider": "openai",
      "model_name": "gpt-5-2025-08-07",
      "display_name": "GPT-5",
      "description": "GPT-5 is our flagship model for coding, reasoning, and agentic tasks across domains.",
      "model_aliases": [
        "GPT-5",
        "gpt-5"
      ],
      "dollars_per_million_tokens_input": 1.25,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-5-chat-latest": {
      "provider": "openai",
      "model_name": "gpt-5-chat-latest",
      "display_name": "gpt-5-chat-latest",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 1.25,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "responses",
      "requires_flat_input": false,
      "temperature_values": [
        1.0
      ],
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": 0,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4.1-mini": {
      "provider": "openai",
      "model_name": "gpt-4.1-mini",
      "display_name": "gpt-4.1-mini",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.4,
      "dollars_per_million_tokens_output": 1.6,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4.1-nano": {
      "provider": "openai",
      "model_name": "gpt-4.1-nano",
      "display_name": "gpt-4.1-nano",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.1,
      "dollars_per_million_tokens_output": 0.4,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o": {
      "provider": "openai",
      "model_name": "gpt-4o",
      "display_name": "gpt-4o",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-2024-05-13": {
      "provider": "openai",
      "model_name": "gpt-4o-2024-05-13",
      "display_name": "gpt-4o-2024-05-13",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 5.0,
      "dollars_per_million_tokens_output": 15.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-mini": {
      "provider": "openai",
      "model_name": "gpt-4o-mini",
      "display_name": "gpt-4o-mini",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.15,
      "dollars_per_million_tokens_output": 0.6,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-realtime": {
      "provider": "openai",
      "model_name": "gpt-realtime",
      "display_name": "gpt-realtime",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 4.0,
      "dollars_per_million_tokens_output": 16.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-realtime-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-realtime-preview",
      "display_name": "gpt-4o-realtime-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 5.0,
      "dollars_per_million_tokens_output": 20.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-mini-realtime-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-mini-realtime-preview",
      "display_name": "gpt-4o-mini-realtime-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.6,
      "dollars_per_million_tokens_output": 2.4,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-audio": {
      "provider": "openai",
      "model_name": "gpt-audio",
      "display_name": "gpt-audio",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-audio-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-audio-preview",
      "display_name": "gpt-4o-audio-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-mini-audio-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-mini-audio-preview",
      "display_name": "gpt-4o-mini-audio-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.15,
      "dollars_per_million_tokens_output": 0.6,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o1": {
      "provider": "openai",
      "model_name": "o1",
      "display_name": "o1",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 15.0,
      "dollars_per_million_tokens_output": 60.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": true,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": [
        1.0
      ],
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": 0,
      "supports_tool_choice": false,
      "tool_call_format": null
    },
    "openai:o1-pro": {
      "provider": "openai",
      "model_name": "o1-pro",
      "display_name": "o1-pro",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 150.0,
      "dollars_per_million_tokens_output": 600.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": true,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": [
        1.0
      ],
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": 0,
      "supports_tool_choice": false,
      "tool_call_format": null
    },
    "openai:o3-pro": {
      "provider": "openai",
      "model_name": "o3-pro",
      "display_name": "o3-pro",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 20.0,
      "dollars_per_million_tokens_output": 80.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o3": {
      "provider": "openai",
      "model_name": "o3",
      "display_name": "o3",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o4-mini": {
      "provider": "openai",
      "model_name": "o4-mini",
      "display_name": "o4-mini",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 1.1,
      "dollars_per_million_tokens_output": 4.4,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o3-mini": {
      "provider": "openai",
      "model_name": "o3-mini",
      "display_name": "o3-mini",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 1.1,
      "dollars_per_million_tokens_output": 1.1,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:o1-mini": {
      "provider": "openai",
      "model_name": "o1-mini",
      "display_name": "o1-mini",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 1.1,
      "dollars_per_million_tokens_output": 4.4,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": true,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": false,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": [
        1.0
      ],
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": 0,
      "supports_tool_choice": false,
      "tool_call_format": null
    },
    "openai:codex-mini-latest": {
      "provider": "openai",
      "model_name": "codex-mini-latest",
      "display_name": "codex-mini-latest",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 1.5,
      "dollars_per_million_tokens_output": 6.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-mini-search-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-mini-search-preview",
      "display_name": "gpt-4o-mini-search-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 0.15,
      "dollars_per_million_tokens_output": 0.6,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-4o-search-preview": {
      "provider": "openai",
      "model_name": "gpt-4o-search-preview",
      "display_name": "gpt-4o-search-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 10.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": 2.0,
      "min_temperature": 0.0,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:computer-use-preview": {
      "provider": "openai",
      "model_name": "computer-use-preview",
      "display_name": "computer-use-preview",
      "description": "",
      "model_aliases": null,
      "dollars_per_million_tokens_input": 3.0,
      "dollars_per_million_tokens_output": 12.0,
      "max_input_tokens": 0,
      "max_output_tokens": null,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "is_reasoning_model": false,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": null,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": null,
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": "chat",
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null
    },
    "openai:gpt-5": {
      "provider": "openai",
      "model_name": "gpt-5",
      "display_name": "GPT-5",
      "description": "GPT-5 is our flagship model for coding, reasoning, and agentic tasks across domains.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 1.25,
      "dollars_per_million_tokens_output": 10.0,
      "dollars_per_million_tokens_cached_input": 0.125,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": true,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": true,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-5-mini": {
      "provider": "openai",
      "model_name": "gpt-5-mini",
      "display_name": "GPT-5 mini",
      "description": "A model from the GPT-5 family, listed in a quick comparison chart.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 0.25,
      "dollars_per_million_tokens_output": 0.25,
      "dollars_per_million_tokens_cached_input": 0.025,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": true,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-5-pro": {
      "provider": "openai",
      "model_name": "gpt-5-pro",
      "display_name": "GPT-5 pro",
      "description": "Version of GPT-5 that produces smarter and more precise responses. It uses more compute to think harder and provide consistently better answers, and is designed for the most advanced reasoning tasks.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 15.0,
      "dollars_per_million_tokens_output": 120.0,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 128000,
      "max_output_tokens": 272000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": true,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:GPT-4.1": {
      "provider": "openai",
      "model_name": "GPT-4.1",
      "display_name": "GPT-4.1",
      "description": "GPT-4.1 excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "dollars_per_million_tokens_cached_input": 0.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 1014788,
      "max_output_tokens": 32768,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:GPT-4o": {
      "provider": "openai",
      "model_name": "GPT-4o",
      "display_name": "GPT-4o",
      "description": null,
      "model_aliases": [],
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 2.5,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "supports_vision": false,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-5-codex": {
      "provider": "openai",
      "model_name": "gpt-5-codex",
      "display_name": "GPT-5-Codex",
      "description": "GPT-5-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments. It's available in the Responses API only and the underlying model snapshot will be regularly updated.",
      "model_aliases": [],
      "dollars_per_million_tokens_input": 1.25,
      "dollars_per_million_tokens_output": 10.0,
      "dollars_per_million_tokens_cached_input": 0.125,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-5-nano-2025-08-07": {
      "provider": "openai",
      "model_name": "gpt-5-nano-2025-08-07",
      "display_name": "GPT-5 nano",
      "description": "GPT-5 Nano is our fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
      "model_aliases": [
        "gpt-5-nano"
      ],
      "dollars_per_million_tokens_input": 0.05,
      "dollars_per_million_tokens_output": 0.4,
      "dollars_per_million_tokens_cached_input": 0.005,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-5-pro-2025-10-06": {
      "provider": "openai",
      "model_name": "gpt-5-pro-2025-10-06",
      "display_name": "GPT-5 pro",
      "description": "GPT-5 pro uses more compute to think harder and provide consistently better answers. GPT-5 pro is available in the Responses API only to enable support for multi-turn model interactions before responding to API requests, and other advanced API features in the future. Since GPT-5 pro is designed to tackle tough problems, some requests may take several minutes to finish. To avoid timeouts, try using background mode. As our most advanced reasoning model, GPT-5 pro defaults to (and only supports) reasoning.effort: high. GPT-5 pro does not support code interpreter.",
      "model_aliases": [
        "gpt-5-pro"
      ],
      "dollars_per_million_tokens_input": 15.0,
      "dollars_per_million_tokens_output": 120.0,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 128000,
      "max_output_tokens": 272000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": true,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o3-deep-research-2025-06-26": {
      "provider": "openai",
      "model_name": "o3-deep-research-2025-06-26",
      "display_name": "o3-deep-research",
      "description": "o3-deep-research is our most advanced model for deep research, designed to tackle complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data\u2014brought in through MCP connectors.",
      "model_aliases": [
        "o3-deep-research"
      ],
      "dollars_per_million_tokens_input": 10.0,
      "dollars_per_million_tokens_output": 40.0,
      "dollars_per_million_tokens_cached_input": 2.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o4-mini-deep-research-2025-06-26": {
      "provider": "openai",
      "model_name": "o4-mini-deep-research-2025-06-26",
      "display_name": "o4-mini-deep-research",
      "description": "o4-mini-deep-research is our faster, more affordable deep research model\u2014ideal for tackling complex, multi-step research tasks. It can search and synthesize information from across the internet as well as from your own data, brought in through MCP connectors.",
      "model_aliases": [
        "o4-mini-deep-research"
      ],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "dollars_per_million_tokens_cached_input": 0.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": false,
      "supports_json_mode": false,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o3-pro-2025-06-10": {
      "provider": "openai",
      "model_name": "o3-pro-2025-06-10",
      "display_name": "o3-pro",
      "description": "The o-series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o3-pro model uses more compute to think harder and provide consistently better answers.\n\no3-pro is available in the Responses API only to enable support for multi-turn model interactions before responding to API requests, and other advanced API features in the future. Since o3-pro is designed to tackle tough problems, some requests may take several minutes to finish. To avoid timeouts, try using background mode.",
      "model_aliases": [
        "o3-pro"
      ],
      "dollars_per_million_tokens_input": 20.0,
      "dollars_per_million_tokens_output": 80.0,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o3-2025-04-16": {
      "provider": "openai",
      "model_name": "o3-2025-04-16",
      "display_name": "o3",
      "description": "o3 is a well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. It also excels at technical writing and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images.",
      "model_aliases": [
        "o3"
      ],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "dollars_per_million_tokens_cached_input": 0.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o4-mini-2025-04-16": {
      "provider": "openai",
      "model_name": "o4-mini-2025-04-16",
      "display_name": "o4-mini",
      "description": "o4-mini is our latest small o-series model. It's optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. It's succeeded by GPT-5 mini.",
      "model_aliases": [
        "o4-mini"
      ],
      "dollars_per_million_tokens_input": 1.1,
      "dollars_per_million_tokens_output": 4.4,
      "dollars_per_million_tokens_cached_input": 0.275,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4.1-2025-04-14": {
      "provider": "openai",
      "model_name": "gpt-4.1-2025-04-14",
      "display_name": "GPT-4.1",
      "description": "GPT-4.1 excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.",
      "model_aliases": [
        "gpt-4.1"
      ],
      "dollars_per_million_tokens_input": 2.0,
      "dollars_per_million_tokens_output": 8.0,
      "dollars_per_million_tokens_cached_input": 0.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 1014808,
      "max_output_tokens": 32768,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4.1-mini-2025-04-14": {
      "provider": "openai",
      "model_name": "gpt-4.1-mini-2025-04-14",
      "display_name": "GPT-4.1 mini",
      "description": "GPT-4.1 mini excels at instruction following and tool calling. It features a 1M token context window, and low latency without a reasoning step. Note that we recommend starting with GPT-5 mini for more complex tasks.",
      "model_aliases": [
        "gpt-4.1-mini"
      ],
      "dollars_per_million_tokens_input": 0.4,
      "dollars_per_million_tokens_output": 1.6,
      "dollars_per_million_tokens_cached_input": 0.1,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 1014808,
      "max_output_tokens": 32768,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4.1-nano-2025-04-14": {
      "provider": "openai",
      "model_name": "gpt-4.1-nano-2025-04-14",
      "display_name": "GPT-4.1 nano",
      "description": "GPT-4.1 nano excels at instruction following and tool calling. It features a 1M token context window, and low latency without a reasoning step. Note that we recommend starting with GPT-5 nano for more complex tasks.",
      "model_aliases": [
        "gpt-4.1-nano"
      ],
      "dollars_per_million_tokens_input": 0.1,
      "dollars_per_million_tokens_output": 0.4,
      "dollars_per_million_tokens_cached_input": 0.025,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 1014808,
      "max_output_tokens": 32768,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o1-pro-2025-03-19": {
      "provider": "openai",
      "model_name": "o1-pro-2025-03-19",
      "display_name": "o1-pro",
      "description": "The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers. o1-pro is available in the Responses API only to enable support for multi-turn model interactions before responding to API requests, and other advanced API features in the future.",
      "model_aliases": [
        "o1-pro"
      ],
      "dollars_per_million_tokens_input": 150.0,
      "dollars_per_million_tokens_output": 600.0,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": false,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o3-mini-2025-01-31": {
      "provider": "openai",
      "model_name": "o3-mini-2025-01-31",
      "display_name": "o3-mini",
      "description": "o3-mini is our newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini supports key developer features, like Structured Outputs, function calling, and Batch API.",
      "model_aliases": [
        "o3-mini"
      ],
      "dollars_per_million_tokens_input": 1.1,
      "dollars_per_million_tokens_output": 4.4,
      "dollars_per_million_tokens_cached_input": 0.55,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": false,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:o1-2024-12-17": {
      "provider": "openai",
      "model_name": "o1-2024-12-17",
      "display_name": "o1",
      "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user.",
      "model_aliases": [
        "o1",
        "o1-preview",
        "o1-preview-2024-09-12"
      ],
      "dollars_per_million_tokens_input": 15.0,
      "dollars_per_million_tokens_output": 60.0,
      "dollars_per_million_tokens_cached_input": 7.5,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 100000,
      "max_output_tokens": 100000,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": true,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4o-2024-08-06": {
      "provider": "openai",
      "model_name": "gpt-4o-2024-08-06",
      "display_name": "GPT-4o",
      "description": "GPT-4o (\u201co\u201d for \u201comni\u201d) is our versatile, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is the best model for most tasks, and is our most capable model outside of our o-series models.",
      "model_aliases": [
        "gpt-4o",
        "gpt-4o-2024-11-20",
        "gpt-4o-2024-05-13"
      ],
      "dollars_per_million_tokens_input": 2.5,
      "dollars_per_million_tokens_output": 10.0,
      "dollars_per_million_tokens_cached_input": 1.25,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 111616,
      "max_output_tokens": 16384,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4o-mini-2024-07-18": {
      "provider": "openai",
      "model_name": "gpt-4o-mini-2024-07-18",
      "display_name": "GPT-4o mini",
      "description": "GPT-4o mini (\u201co\u201d for \u201comni\u201d) is a fast, affordable small model for focused tasks. It accepts both text and image inputs, and produces text outputs (including Structured Outputs). It is ideal for fine-tuning, and model outputs from a larger model like GPT-4o can be distilled to GPT-4o-mini to produce similar results at lower cost and latency.",
      "model_aliases": [
        "gpt-4o-mini"
      ],
      "dollars_per_million_tokens_input": 0.15,
      "dollars_per_million_tokens_output": 0.6,
      "dollars_per_million_tokens_cached_input": 0.075,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 111616,
      "max_output_tokens": 16384,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": true,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    },
    "openai:gpt-4-turbo-2024-04-09": {
      "provider": "openai",
      "model_name": "gpt-4-turbo-2024-04-09",
      "display_name": "GPT-4 Turbo",
      "description": "GPT-4 Turbo is the next generation of GPT-4, an older high-intelligence GPT model. It was designed to be a cheaper, better version of GPT-4. Today, we recommend using a newer model like GPT-4o.",
      "model_aliases": [
        "gpt-4-turbo",
        "gpt-4-turbo-preview",
        "gpt-4-0125-preview",
        "gpt-4-1106-vision-preview"
      ],
      "dollars_per_million_tokens_input": 10.0,
      "dollars_per_million_tokens_output": 30.0,
      "dollars_per_million_tokens_cached_input": null,
      "dollars_per_million_tokens_cache_write_5m": null,
      "dollars_per_million_tokens_cache_write_1h": null,
      "dollars_per_million_tokens_cache_read": null,
      "dollars_per_million_tokens_input_long_context": null,
      "dollars_per_million_tokens_output_long_context": null,
      "dollars_per_million_tokens_output_thinking": null,
      "cache_storage_cost_per_million_tokens_per_hour": null,
      "long_context_threshold_tokens": null,
      "max_input_tokens": 123904,
      "max_output_tokens": 4096,
      "supports_vision": true,
      "supports_function_calling": true,
      "supports_json_mode": true,
      "supports_parallel_tool_calls": false,
      "supports_streaming": true,
      "supports_audio": false,
      "supports_documents": false,
      "supports_json_schema": false,
      "supports_logprobs": false,
      "supports_multiple_responses": false,
      "supports_caching": false,
      "supports_thinking": false,
      "supports_long_context_pricing": false,
      "is_reasoning_model": false,
      "supports_temperature": true,
      "supports_system_message": true,
      "supports_pdf_input": false,
      "api_endpoint": null,
      "requires_flat_input": false,
      "temperature_values": null,
      "max_temperature": null,
      "min_temperature": null,
      "max_tools": null,
      "supports_tool_choice": true,
      "tool_call_format": null,
      "speed_tier": null,
      "intelligence_tier": null,
      "requires_tier": 0,
      "requires_waitlist": false,
      "model_family": null,
      "recommended_use_cases": [],
      "is_active": true,
      "release_date": null,
      "deprecated_date": null,
      "added_date": null
    }
  },
  "version": 4,
  "updated_at": "2025-10-12T20:17:31.236654",
  "content_sha256_jcs": "a32c4363b0e702bce9139f55c928b190a69d3cc23d46a04f631f29d71ee15c0c"
}
